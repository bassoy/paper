\section{Algorithm Design}
\label{sec:design}
\subsection{Sequential Baseline Algorithm}
The sequential baseline algorithm implementing Eq. \ref{equ:tensor.matrix.multplication} can be implemented with a single C++ function.
It consists of nested recursion with a control flow that resembles algorithm 1 in \cite{bassoy:2018:fast}, consisting of two \ttt{if} statements with an \ttt{else} branch.
The body of the first \ttt{if} statement contains a recursive call that skips the iteration over the dimension $n_q$ if $r = \mhq$ with $\mhq = \mbpi^{-1}_q$ where $\mbpi^{-1}$ is the inverse layout tuple.
The second \ttt{if} statement contains multiple recursive calls for the modes $1 \leq r \neq \mhq \leq p$ with different multi-indices.
Note that the second \ttt{if} statement is skipped for $q = \pi_1$ as the condition of the first one is evaluated to true.
The \ttt{else} branch is the base case and consists of two loops that compute a fiber-matrix product.
The inner loop iterates over the dimension $n_q$ of $\mubA$ and $\mbB$ with index $1\leq i_q \leq n_q$ computing an inner product.
The outer loop iterates over the dimension $m$ of $\mubC$ and $\mbB$ with index $1 \leq j \leq m$.
The baseline algorithm supports tensors with arbitrary order, dimensions and any non-hierarchical storage format.

\subsection{Modified Baseline Algorithm with Contiguous Memory Access}
The baseline algorithm accesses memory of $\mubA$ and $\mubC$ non-contiguously whenever $\pi_1 \neq q$ so that indices $i_q$ and $j$ are incremented with steps greater than one.
Matrix $\mbB$ is contiguously accessed if $i_q$ or $j$ is incremented with unit-steps depending on the storage format of $\mubB$.
The access pattern could be improved by reordering tensor elements according to the storage format which results in copy operations reducing the overall throughput of the operation \cite{shi:2016:tensor.contraction}.

A better approach is to access tensor elements according to the tensor layout using the permutation tuple $\mbpi$ as proposed in \cite{bassoy:2018:fast}.
The modified algorithm with contiguous memory accesses is given in algorithm \ref{alg:ttm.sequential.coalesced} for $\pi_1 \neq q$ and $p > 1$.
Each recursion level adjusts only one multi-index element $\mbi(\pi_r)$ with a stride $\mbw(\pi_r)$ as depicted in line 5.
With increasing recursion level and decreasing $r$, indices are incremented with smaller step sizes as $\mbw(\pi_r) \leq \mbw(\pi_{r+1})$. 
The condition of the second \ttt{if} statement in line 4 is changed from $r \geq 1$ to $r > 1$.
In this way, the loop incrementing with index $\mbpi(\pi_1)$ with the minimum stride $\mbw(\mbpi_1)$ can be included in the base case.
The base case therefore contains three loops performing a slice-matrix multiplication. 
The ordering of the three loops within the base case are adjusted according to the tensor and matrix layout.
The inner-most loop increments $\mbi(\pi_1)$ and therefore contiguously accesses tensor elements of $\mubA$ and $\mubC$.
The second loop increments $i_q$ with which elements of $\mbB$ are contiguously accessed if $\mbB$ is stored in the row-major format.
The third loop increments $j$ and could be placed as the second loop if $\mbB$ is stored in the column-major format.
The simple ordering of the three loops is discussed in \cite{golub:2013:matrix.computations}.

\begin{algorithm}[t]
%\SetAlgoNoLine
\DontPrintSemicolon
\SetKwProg{Fn}{}{}{end}
\SetKwFunction{function}{tensor\_times\_matrix}%
%\SetAlgoNoEnd
\footnotesize 
\SetAlgoVlined
\hrule
\BlankLine
\Fn{\function{$\mubA, \mbB, \mubC, \mbn, \mbi, m, q, \hat{q}, r$}}
{
	\uIf{$r = \hat{q}$ }
	{
		\function{$\mubA, \mbB, \mubC, \mbn, \mbi, q, \hat{q}, r-1$ }
	}
	\uElseIf{$r > 1$ }
	{
		\For{$i_{\pi_r} \leftarrow 1$ \KwTo $ n_{\pi_r}$}
		{
			\function{$\mubA, \mbB, \mubC, \mbn, \mbi, q, \hat{q}, r-1$}\;
		}		
	}	
	\Else%{$r\geq1 \wedge m \neq 1$}
	{
		\For{$j \leftarrow 1$ \KwTo $m$}
		{
			\For{$i_q \leftarrow 1$ \KwTo $n_q$}
			{			
				\For{$i_{\pi_1} \leftarrow 1$ \KwTo $n_{\pi_1}$}
				{
					$\mubC(i_1,...,i_{q-1},j,i_{q+1},...,i_{p})$ \ttt{+=} $\mubA(i_1,...,i_q,...,i_p) \cdot \mbB(j,i_q)$\;
				}
			}
		}
	}
}
\BlankLine
\hrule
\caption{
\footnotesize %
Modified baseline algorithm with contiguous memory access for the tensor-matrix multiplication.
The tensor order must be greater than one and for the contraction mode $1 \leq q \leq p$ and $\pi_1 \neq q$ must hold.
The algorithm needs to be initially called with $r=p$ where $\mbn$ is the shape tuple of $\mubA$ and $m$ is the $q$-th dimension of $\mubC$. 
Iteration along mode $\mhq$ with $\mhq = \mbpi^{-1}_q$ is moved into the inner-most recursion level.
\label{alg:ttm.sequential.coalesced}
}
\end{algorithm}

While the spatial data locality is improved by adjusting the loop ordering, the temporal data locality of tensors $\mubA$ and $\mubC$ differ.
Note that slice $\mubA(..,i_{\pi_1},..i_q,..)$ is accessed $m$ times, fiber $\mubC(..,i_{\pi_1},..)$ is accessed $\mbn(q)$ times and element $\mubB(j,i_q)$ is accessed $\mbn(\pi_1)$ times.
While the specified fiber of $\mubC$ can fit into first or second level cache, slice elements of $\mubA$ are unlikely to fit in the local caches if the slice size $n_{\pi_1} \times n_q$ is large leading to higher cache misses and suboptimal performance.
%TODO: hier mehr paper, die BLAS Implementierung referenzieren?
Optimized tiling for better temporal data locality has been discussed in \cite{goto:2008:gemm} which suggests to use existing high-performance BLAS implementations.
The proposed algorithm therefore constitutes the starting point for \tf{BLAS} utilization within the base case.

\subsection{Extended Algorithms utilizing BLAS}
\label{subsec:linear.algebra.routines}
\vspace{-0.3em}
We apply highly optimized routines to fully or partly execute tensor contractions as it is done in \cite{li:2015:input, shi:2016:tensor.contraction}.
The function and parameter configurations for the tensor multiplication can be divided into eight cases.

\tit{Case 1 $(p=1)$:}
The tensor-vector product $\mubA \times_1 \mbb$ can be computed with a \tf{DOT} operation $\mba^T \mbb$ where $\mubA$ is an order-$1$ tensor, i.e. a vector $\mba$ of length $n_1$.

\tit{Case 2-5 $(p=2)$:}
Let $\mbA$ be an order-$2$ tensor, i.e. matrix with dimensions $n_1$ and $n_2$.
If $m=2$ and if $\mbA$ is stored according to the column-major $\mbpi=(1,2)$ or row-major format $\mbpi=(2,1)$, the tensor-vector multiplication can be trivially executed by a \tf{GEMV} routine using the tensor's storage format.
The two remaining cases for $m=1$ require an interpretation of the order-$2$ tensor. 
In case of the column-major format $\mbpi=(1,2)$, the tensor-vector product can be computed with a \tf{GEMV} routine, interpreting the columns of the matrix as rows with permuted dimensions.
Analogously, a \tf{GEMV} routine executes a tensor-vector multiplication with $\mbpi=(2,1)$.

%\paragraph{Case 6-7 ($p>2$):}
%\label{subsubsec:order.p.ge.1}
\tit{Case 6-7 $(p>2)$:}
General tensor-vector multiplications with higher-order tensors execute the \tf{GEMV} routine multiple times over different slices of the tensor.
There are two exceptions to the general case.%, namely when $\pi_1$ or $\pi_p$ is equal to the contraction mode $q$.
If $\pi_1 = q$, a single \tf{GEMV} routine is sufficient for any storage layout.
The tensor can be interpreted as a matrix with $\bar{n}_q = \prod_{r=1}^p n_r / n_q$ rows and $n_q$ columns.
The leading dimension \tf{LDA} for $\pi_1=q$ is $n_q$.
Tensor fibers with contiguously stored elements are therefore interpreted as matrix rows.
In case of $\pi_p=q$, the leading dimension \tf{LDA} is given by $\bar{n}_q$ where all fibers with the exception of the dimension $\pi_p$ are interpreted as matrix columns.
The interpretation of tensor objects does not copy data elements.

\begin{table}[t]
%\captionsetup{width=0.7\textheight}
\centering
%\footnotesize
\footnotesize
\begin{tabular}{ c c c c c c c c c c c } % 
\toprule
Case \ & Order $p$ \ \ & Layout $\mbpi$  & Mode $q$ & Routine \ & \tf{FORMAT} \ & \tf{M} & \tf{N} & \tf{LDA} \\
\midrule
1 & $1$       & -           & $1$       & \tf{DOT}    & -        & $n_1$   & -     & -  \\ %[0.1cm]
\midrule
2 & $2$ & $(1,2)$     & $1$       & \tf{GEMV} & \tf{ROW} & $n_2$ & $n_1$ & $n_1$ \\ %[0.1cm]
3 & $2$ & $(1,2)$     & $2$       & \tf{GEMV} & \tf{COL} & $n_1$ & $n_2$ & $n_1$ \\ %[0.1cm]
4 & $2$ & $(2,1)$     & $1$       & \tf{GEMV} & \tf{COL} & $n_2$ & $n_1$ & $n_2$ \\ %[0.1cm]
5 & $2$ & $(2,1)$     & $2$       & \tf{GEMV} & \tf{ROW} & $n_1$ & $n_2$ & $n_2$ \\ %[0.1cm]
\midrule
6 & $>2$ & any & $\pi_1$  & \tf{GEMV} & \tf{ROW} & $\bar{n}_q$ & $n_q$ & $n_q$ \\ %[0.1cm]
7 & $>2$ & any & $\pi_p$  & \tf{GEMV} & \tf{COL} & $\bar{n}_q$ & $n_q$ & $\bar{n}_q$ \\ %[0.1cm]
\midrule
8 & $>2$ & any & \ $\pi_2,\pi_3,\dots,\pi_{p-1}$ \ & \tf{GEMV*} & \tf{COL} & $\hat{n}_q$ & $n_q$ & $\hat{n}_q$\\%[0.1cm]
%\midrule
%$>2$      & any    & \ $\pi_2,\pi_3,\dots,\pi_{p-1}$ \ & \tf{GEMV}* & \tf{COL} & $w_q$ & $n_q$ & $w_q$\\ [0.1cm]
\bottomrule\\
\end{tabular}
%\vspace{0.2cm}
\caption%
{%
\footnotesize
Parameter configuration of the \tf{DOT}- and \tf{GEMV} with eight cases executing a tensor-vector multiplication with respect to the order $p$, layout $\mbpi$ and contraction mode $q$.
All three parameters determine the values of \tf{FORMAT}, \tf{M}, \tf{N} and \tf{LDA}.
\tf{GEMV*} denotes a multiple execution of \tf{GEMV} with different tensor slices.
In case of order-$2$ and order-$\mhq$ slices, the number of rows must be equal to $\hat{n}_q = n_{\pi_1}$ and $\hat{n}_q =w_q$, respectively.
The number of rows for case 6 and 7 is given by $\bar{n}_q = \prod_{r=1}^p n_r / n_q$.
%\vspace{-0.5cm}
}
\label{tab:mapping}
\end{table}%\textbf{}

\tit{Case 8 $(p>2)$:}
For the last case with $\pi_1\neq q$ and $\pi_p \neq q$, we provide two methods that loop over tensor slices.
%\vspace{-0.35cm}
%\paragraph{Multi-Loop (v1) with Order-$2$ Slices:}
%\cem{Besserer Ãœbergang} 
Lines 8 to 10 of Algorithm \ref{alg:ttv.sequential.blocked} perform a slice-vector multiplication of the form $\mbc' = \mbA' \cdot \mbb$.
It is executed with a \tf{GEMV} with no further adjustment of the algorithm.
The vector $\mbc'$ denotes a fiber of $\mubC$ with $n_u$ elements and $\mbA'$ denotes an order-$2$ slice of $\mubA$ with dimensions $n_u$ and $n_v$ such that
\begin{equation}
\label{equ:order.2.slice}
\mbA' = \mubA(i_1,\dots,\colon_{\mkern-5.5muu},\dots,\colon_{\mkern-5.5muv},\dots,i_p) 
\quad \text{and} \quad
\mbc' = \mubC(i_1,\dots,\colon_{\mkern-5.5muu},\dots,i_p)
\end{equation}
where $u=\pi_1$ and $v = q$ or vice versa.
%\vspace{-0.3cm}
%\paragraph{Multi-Loop (v2) with Order-$\mhq$ Slices:}
Algorithm \ref{alg:ttv.sequential.blocked} needs a minor modification in order to loop over order-$\mhq$ slices. 
With $\mhq = (\pi^{-1})_q$, the conditions in line 2 and 4 are changed to $1 < r \leq \mhq$ and $\mhq < r$, respectively.
The modified algorithms therefore omits the first $\mhq$ modes $\pi_1, \dots, \pi_{\mhq}$ including $\pi_{\mhq} = q$ where all elements of an order-$\mhq$ slice are contiguously stored.
Choosing the first-order storage format for convenience, the order-$\mhq$ and order-$(\mhq-1)$ slices of both tensors are given by 
\begin{equation}
\label{equ:order.mhq.slice}
\mubA' = \mubA(\colon_{\mkern-5.5mu1},\dots,\colon_{\mkern-5.5muq},i_{q+1},\dots,i_{p}) 
\ \text{and} \
\mubC' = \mubC(\colon_{\mkern-5.5mu1},\dots,\colon_{\mkern-5.5mu{q-1}},i_{q+1},\dots,i_p).
\end{equation}
The fiber $\mbc'$ of length $w_q = n_{1} \cdot n_2 \cdots n_{q-1}$ is the one-dimensional interpretation of $\mubC'$ and the order-$2$ slice $\mbA'$ with dimensions $w_q$ and $n_q$ the two-dimensional interpretation of $\mubA'$.
The slice-vector multiplication in this case can be performed with a \tf{GEMV} that interprets the order-$\mhq$ slices as order-$2$ according to the description.
Table~\ref{tab:mapping} summarizes the call parameters of the \tf{DOT} or \tf{GEMV} for all order, storage format and contraction mode combinations.
%The final function \ttt{tensor}\-\ttt{\_}\-\ttt{times}\-\ttt{\_}\-\ttt{vector} integrates all eight cases and executes either one of the first seven cases calling a single optimized and parallel \tf{DOT}/\tf{GEMV} or a recursive/iterative version of Algorithm~\ref{alg:ttv.sequential.blocked} either using one of the two parallel multi-loop versions for the last case.

%\todo[noline]{Could we do also tensor transposition?}.
%Table \ref{tab:mapping} extends the finding in \cite{dinapoli:2014:towards.efficient.use} precisely defining the mapping for any storage format. 
%It also complies with the findings in \cite{li:2015:input}.


\subsection{Parallel Algorithms with Slice-Vector Multiplications}
\label{subsec:parallel.multi-loops}
A straight-forward approach for generating a parallel version of Algorithm \ref{alg:ttv.sequential.blocked} is to divide the outer-most $\pi_p$-th loop into equally sized iterations and execute them in parallel using the \tf{OpenMP} \tf{parallel} \tf{for} directive\cite{bassoy:2018:fast}.
%parallelize the multi-loops in case 8 is described by \cite{bassoy:2018:fast} where the outer-most $\pi_p$-th loop is divided into chunks of the same length. 
With no critical sections and synchronization points, all threads within the parallel region execute their own sequential slice-vector multiplications.
The outer-most dimension $n_{\pi_p}$ determines the degree of parallelism, i.e. the number of parallel threads executing their own instruction stream.


%Yet, the number of parallelizable dimensions are dynamic and depend on the contraction mode $q$ and the storage layout of the tensor.
%Considering Algorithm \ref{alg:ttv.sequential.blocked} executing slice-vector multiplications with order-$2$ slices.
%The degree of parallelism can be improved by e.g. selecting other or additional loops.
Fusing additional loops into a single one improves the degree of parallelism.
%that are not required by the slice-vector multiplication in order to achieve a higher degree of parallelism.
The number of fusible loops depends on the tensor order $p$ and contraction mode $q$ of the tensor-vector multiplication with $\mhq = (\pi^{-1})_q$.
In case of mode-$q$ slice-vector multiplications, loops $\pi_{\mhq+1}, \dots, \pi_{p}$ are not involved in the multiplications and can be transformed into one single loop.
For mode-$2$ slice-vector multiplications all loops except $\pi_1$ and $\pi_{\mhq}$ can be fused.
%Moreover, the fused loops are not required by a slice-vector multiplication.
When all fusible loops are lexically present and both parameters are known before compile time, loop fusion and parallel execution can be easily accomplished with the \tf{OpenMP} \tf{collapse} directive.
The authors of \cite{li:2015:input} use this approach to generate parallel tensor-matrix functions.

%\paragraph{Multi-Loop with Order-$\mhq$ Slices}
%The parallelization of additional loops yields a higher degree of parallelism.
With variable number of dimensions and a variable contraction mode, the iteration count of slice-vector multiplications and the slice selection needs to be determined at compile or run time.
%The number of iterations of the fused loop is determined by the product of the outer dimensions and the increment is given by the slice size.
If $\bar{n}$ is the number of tensor elements of $\mubA$, the total number of slice-vector multiplications with mode-$\mhq$ slices is given by $\bar{n}' = \bar{n} / w_{q}$.
%\begin{equation}
%\begin{split}
%\bar{n}' & = n_{\pi_{k+1}} \cdot n_{\pi_{k+2}} \cdots n_{\pi_{p}} \\
%         & = \bar{n} / w_{m}
%\end{split}
%\end{equation}
%$\bar{n}_{k+1} = n_{\pi_{k+1}} \cdot n_{\pi_{k+2}} \cdots n_{\pi_{p}}$.
Using Eq. \eqref{equ:stride.tuple}, the strides for the iteration are given by $w_{\pi_{\mhq+1}}$ for $\mubA$ and $v_{\pi_{\mhq}}$ for $\mubC$.
In summary, one single parallel outer loop with an iteration count $\bar{n}'$ and an increment variable $j$ iteratively calls mode-$\mhq$ slice-vector multiplications with adjusted memory location $j \cdot w_{\pi_{\mhq+1}}$ and $j \cdot v_{\pi_{\mhq}}$ for $\mubA$ and $\mubC$, respectively.
The degree of parallelism $\prod_{r=\mhq+1}^p n_r$ decreases with increasing $\mhq$ and corresponds for $\mhq = p-1$ to the first parallel version. 
Tensor-vector multiplications with mode-$2$ slice-vector multiplications are further optimized by fusing additional $\mhq-2$ loops.
%The layout, shape and stride tuples of $\mubA$ and $\mubC$ need to be divided in two parts.
%Those without the modes $\pi_1$ and $\pi_q$ are needed to select order-$2$ slices by transforming the iteration index to relative memory locations of an order-$2$ slice with $\lambda_{\mbv''} \circ \gamma \circ \lambda^{-1}_{\mbw''}$.\todo{still need to finish this.}


\begin{comment}
Then
\begin{equation}
\mbpsi = 
\begin{cases}
(1,2) & \text{if} \ \pi_1 < \pi_k\\
(2,1) & \text{otherwise.}
\end{cases}
\end{equation}
\end{comment}

\begin{comment}
\begin{equation}
\begin{array}{lllll}
\pi_i''     &=& \pi_i   &\quad \text{if} & \quad \pi_i < \pi_1 \wedge \pi_i < \pi_k \\
\pi_{i-1}'' &=& \pi_i-1 &\quad \text{if} & \quad (\pi_i > \pi_1 \wedge \pi_i < \pi_k) \vee (\pi_i < \pi_1 \wedge \pi_i > \pi_k) \\
\pi_{i-2}'' &=& \pi_i-2 &\quad \text{if} & \quad \pi_i > \pi_1 \wedge \pi_i > \pi_k \\
\end{array}
\end{equation}
\end{comment}





\begin{comment}
\begin{algorithm}[t]
%\SetAlgoNoLine
\DontPrintSemicolon
\SetKwProg{Fn}{}{}{end}
\SetKwFunction{TTV}{tensor\_times\_vector}%
\SetAlgoVlined
\hrule
\BlankLine
\Fn{\TTV{$\mubA, \mbb, \mubC, \mbn, \mbi, \mbpi, q, r$}}
{
\uIf{$r > 1$ }
{
\For{$i_{\pi_r} \leftarrow 1$ \KwTo $ n_{\pi_r}$}
{
\TTV{$\mubA, \mbb, \mubC, \mbn, \mbi, \mbpi, q, r-1$}\;
}		
}	
\Else%{$r\geq1 \wedge m \neq 1$}
{			
\For{$i_{\mbpi_1} \leftarrow 1$ \KwTo $n_{\mbpi_1}$}
{
$\mubC(i_1,\dots,i_{q-1},i_{q+1},\dots,i_{p})$ \ttt{+=} $\mubA(i_1,\dots,i_q,\dots,i_p) \cdot \mbb(i_q)$\;			
}
}
}
\BlankLine
\hrule
\caption{
\footnotesize Sequential version of the mode-$q$ tensor-vector multiplication  with contiguous memory access for tensors with any order $p\geq 2$ and any non-hierarchical storage format. The function initially called with $r=p$ recursively loops over the complete multi-index space of $\mubA$ and $\mubC$.
\label{alg:ttv.sequential.coalesced}
}
\end{algorithm}
\end{comment}
