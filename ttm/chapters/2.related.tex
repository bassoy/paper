\section{Related Work}
\label{sec:related}


The authors in \cite{dinapoli:2014:towards.efficient.use} discuss the efficient tensor contractions with highly optimized \tf{BLAS}. 
%They describe a slicing technique of tensors for using BLAS. 
%With a set of requirements they define three contraction categories.
Based on the \tf{LOG} approach, they define requirements for the use of \tf{GEMM} for class 3 tensor contractions and provide slicing techniques for tensors. %  when both arguments exhibit free indices
The slicing recipe for the class 2 categorized tensor contractions contains a short description with a rule of thumb for maximizing performance.
%Compared to class 3 operations, the tensor-vector multiplication receives less attention.
Runtime measurements cover class 3 tensor contractions.
%todo: weg und was anderes, zum Beispiel mein eigenes Paper

The authors of \cite{springer:2018:design} present a tensor-contraction generator \tf{TCCG} and the \tf{GETT} approach for dense tensor contractions that is inspired from the design of a high-performance \tf{GEMM}.
Their unified code generator selects implementations from generated \tf{GETT}, \tf{LoG} and \tf{TTGT} candidates.
Their findings show that among $48$ different contractions $15$\% of \tf{LoG}-based implementations are the fastest.

The author presents in \cite{matthews:2018:high} a runtime flexible tensor contraction library that uses \tf{GETT} approach as well.
He describes block-scatter-matrix algorithm which uses a special layout for the tensor contraction.
The proposed algorithm yields results that feature a similar runtime behavior to those presented in \cite{springer:2018:design}.

The work in \cite{li:2015:input} presents a framework that generates in-place tensor-matrix multiplication according to the \tf{LOG} approach. 
The authors present two strategies for efficiently computing the tensor contraction applying \tf{GEMM}s with tensors.
They report a speedup of up to $4$x over the \tf{TTGT}-based \tf{MATLAB} tensor toolbox library discussed in \cite{bader:2006:algorithm862}.
%Although many aspects are similar to our work, the authors emphasize the code generation of tensor-matrix multiplications using high-performance \tf{GEMM}'s.
%todo: hier besser sagen, welche Konzepte wir hierfür übernehmen.


In \cite{bassoy:2019:ttv}, the author presents LoG-based algorithms that compute the tensor-vector product. 
The presented algorithms are flexible and support dense tensors with linear tensor layouts.



a runtime flexible library is presented tensor-
