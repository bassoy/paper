\section{Algorithm Design}
\label{sec:design}
\subsection{Baseline Algorithm with Contiguous Memory Access}
\label{sec:design:modified.baseline.algorithm}
The tensor-times-matrix multiplication in equation \ref{equ:tensor.matrix.multplication} can be implemented with one sequential algorithm using a nested recursion \cite{bassoy:2018:fast}.
It consists of two \ttt{if} statements with an \ttt{else} branch that computes a fiber-matrix product with two loops.
The outer loop iterates over the dimension $m$ of $\mubC$ and $\mbB$, while the inner iterates over dimension $n_q$ of $\mubA$ and $\mbB$ computing an inner product with fibers of $\mubA$ and $\mbB$. 
While matrix $\mbB$ can be accessed contiguously depending on its storage format, elements of $\mubA$ and $\mubC$ are accessed non-contiguously if $\pi_1 \neq q$.

%The access pattern can be improved by reordering tensor elements according to the storage format.
%However, copy operations reduce the overall throughput of the operation, see \cite{shi:2016:tensor.contraction}.


A better approach is illustrated in algorithm \ref{alg:ttm.sequential.coalesced} where the loop order is adjust to the tensor layout tuple $\mbpi$ and memory is accessed contiguously for $\pi_1 \neq q$ and $p > 1$.
The adjustment of the loop order is accomplished in line 5 which uses the layout tuple $\mbpi$ to select a multi-index element $i_{\pi_r}$ and to increment it with the corresponding stride $w_{\pi_r}$.
Hence, with increasing recursion level and decreasing $r$, indices are incremented with smaller strides as $w_{\pi_r} \leq w_{\pi_{r+1}}$.
%The condition of the second \ttt{if} statement in line 4 is changed from $r \geq 1$ to $r > 1$.
The second \tf{if} statement in line number 4 allows the loop over mode $\pi_1$ to be placed into the base case which contains three loops performing a slice-matrix multiplication.
%the minimum stride $w_{\pi_1}$ to be included in the base case.
%The latter now contains three loops performing a slice-matrix multiplication. 
%The loop ordering are adjusted according to the tensor and matrix layout.
In this way, the inner-most loop is able to increment $i_{\pi_1}$ with a unit stride and contiguously accesses tensor elements of $\mubA$ and $\mubC$.
The second loop increments $i_q$ with which elements of $\mbB$ are contiguously accessed if $\mbB$ is stored in the row-major format.
The third loop increments $j$ and could be placed as the second loop if $\mbB$ is stored in the column-major format.
%The loop ordering are adjusted according to the tensor and matrix layout.
%The simple ordering of the three loops is discussed in \cite{golub:2013:matrix.computations}.

\begin{algorithm}[t]
%\SetAlgoNoLine
\DontPrintSemicolon
\SetKwProg{Fn}{}{}{end}
\SetKwFunction{function}{ttm}%
%\SetAlgoNoEnd
\footnotesize 
\SetAlgoVlined
\hrule
\BlankLine
\Fn{\function{$\mubA, \mbB, \mubC, \mbn, \mbi, m, q, \mhq, r$}}
{
	\uIf{$r = \mhq$ }
	{
		\function{$\mubA, \mbB, \mubC, \mbn, \mbi, m, q, \mhq, r-1$ }
	}
	\uElseIf{$r > 1$ }
	{
		\For{$i_{\pi_r} \leftarrow 1$ \KwTo $ n_{\pi_r}$}
		{
			\function{$\mubA, \mbB, \mubC, \mbn, \mbi, m, q, \mhq, r-1$}\;
		}		
	}	
	\Else%{$r\geq1 \wedge m \neq 1$}
	{
		\For{$j \leftarrow 1$ \KwTo $m$}
		{
			\For{$i_q \leftarrow 1$ \KwTo $n_q$}
			{			
				\For{$i_{\pi_1} \leftarrow 1$ \KwTo $n_{\pi_1}$}
				{
					$\mubC([\mbi_1,j,\mbi_2])$ \ttt{+=} $\mubA([\mbi_1,i_q,\mbi_2]) \cdot \mbB(j,i_q)$\;
				}
			}
		}
	}
}
\BlankLine
\hrule
\caption{
\footnotesize %
Modified baseline algorithm with contiguous memory access for the tensor-matrix multiplication.
The tensor order $p$ must be greater than $1$ and the contraction mode $q$ must satisfy $1 \leq q \leq p$ and $\pi_1 \neq q$.
The initial call must happen with $r=p$ where $\mbn$ is the shape tuple of $\mubA$ and $m$ is the $q$-th dimension of $\mubC$. 
%Iteration along mode $q$ with $\mhq = \mbpi^{-1}_q$ is moved into the inner-most recursion level.
\label{alg:ttm.sequential.coalesced}
}
\end{algorithm}

While spatial data locality is improved by adjusting the loop ordering, slices $\mubA_{\pi_1,q}'$, fibers $\mubC_{\pi_1}'$ and elements $\mubB(j,i_q)$ are accessed $m$, $n_q$ and $n_{\pi_1}$ times, respectively.
The specified fiber of $\mubC$ might fit into first or second level cache, slice elements of $\mubA$ are unlikely to fit in the local caches if the slice size $n_{\pi_1} \times n_q$ is large, leading to higher cache misses and suboptimal performance.
Instead of optimizing for better temporal data locality, we use existing high-performance BLAS implementations for the base case.
The following subsection explains this approach.

\subsection{BLAS-based Algorithms with Tensor Slices}
\label{sec:design:blas.based.algorithm.slices}
%\vspace{-0.3em}
\begin{table*}[t]
	%\captionsetup{width=0.7\textheight}
	\centering
	\footnotesize
	%\scriptsize
	\begin{tabular}{ c c c c c c c c c c c c c c c } % 
		\toprule
		Case & Order $p$ & Layout $\mbpi_{\mubA,\mubC}$ & Layout $\mbpi_{\mbB}$ & Mode $q$ & Routine & \tf{T} & \tf{M} & \tf{N} & \tf{K} & \tf{A} & \tf{LDA} & \tf{B} & \tf{LDB} & \tf{LDC} \\
		\midrule
		1 & $1$ & -       & \tf{rm/cm} & $1$      & \tf{gemv} & -       & $m$   & $n_1$ & -     & $\mbB$  & $n_1$ & $\mubA$  & - & - \\
		\midrule
		2 & $2$ & \tf{cm} & \tf{rm} & $1$      & \tf{gemm} & $\mbB$  & $n_2$ & $m$   & $n_1$ & $\mubA$ & $n_1$ & $\mbB$   & $n_1$ & $m$   \\
		& $2$ & \tf{cm} & \tf{cm} & $1$      & \tf{gemm} & -       & $m$   & $n_2$ & $n_1$ & $\mbB$  & $m$   & $\mubA$  & $n_1$ & $m$   \\
		3 & $2$ & \tf{cm} & \tf{rm} & $2$      & \tf{gemm} & -       & $m$   & $n_1$ & $n_2$ & $\mbB$  & $n_2$ & $\mubA$  & $n_1$ & $n_1$ \\
		& $2$ & \tf{cm} & \tf{cm} & $2$      & \tf{gemm} & $\mbB$  & $n_1$ & $m$   & $n_2$ & $\mubA$ & $n_1$ & $\mbB$   & $m$   & $n_1$ \\  
		4 & $2$ & \tf{rm} & \tf{rm} & $1$      & \tf{gemm} & -       & $m$   & $n_2$ & $n_1$ & $\mbB$  & $n_1$ & $\mubA$  & $n_2$ & $n_2$ \\
		& $2$ & \tf{rm} & \tf{cm} & $1$      & \tf{gemm} & $\mbB$  & $n_2$ & $m$   & $n_1$ & $\mubA$ & $n_2$ & $\mbB$   & $m$   & $n_2$ \\
		5 & $2$ & \tf{rm} & \tf{rm} & $2$      & \tf{gemm} & $\mbB$  & $n_1$ & $m$   & $n_2$ & $\mubA$ & $n_2$ & $\mbB$   & $n_2$ & $m$   \\
		& $2$ & \tf{rm} & \tf{cm} & $2$      & \tf{gemm} &         & $m$   & $n_1$ & $n_2$ & $\mbB$  & $m$   & $\mubA$  & $n_2$ & $m$   \\
		\midrule
		6 & $>2$ & any    & \tf{rm} & $\pi_1$  & \tf{gemm} & $\mbB$  & $\mbnq$ & $m$     & $n_q$ & $\mubA$ & $n_q$   & $\mbB$  & $n_q$   & $m$\\
		& $>2$ & any    & \tf{cm} & $\pi_1$  & \tf{gemm} & -       & $m$     & $\mbnq$ & $n_q$ & $\mbB$  & $m$     & $\mubA$ & $n_q$   & $m$\\
		7 & $>2$ & any    & \tf{rm} & $\pi_p$  & \tf{gemm} & -       & $m$     & $\mbnq$ & $n_q$ & $\mbB$  & $n_q$   & $\mubA$ & $\mbnq$ & $\mbnq$ \\
		& $>2$ & any    & \tf{cm} & $\pi_p$  & \tf{gemm} & $\mbB$  & $\mbnq$ & $m$     & $n_q$ & $\mubA$ & $\mbnq$ & $\mbB$  & $m$     & $\mbnq$ \\
		\midrule
		8 & $>2$ & any    & \tf{rm} & $\pi_2,..,\pi_{p-1}$ & \tf{gemm*} & -      & $m$ & $n_{\pi_1}$ & $n_q$ & $\mbB$  & $n_q$ & $\mubA$ & $w_q$ & $w_q$ \\
		& $>2$ & any    & \tf{cm} & $\pi_2,..,\pi_{p-1}$ & \tf{gemm*} & $\mbB$ & $n_{\pi_1}$ & $m$ & $n_q$ & $\mubA$ & $w_q$ & $\mbB$  & $m$   & $w_q$ \\
		\bottomrule
	\end{tabular}
	%\vspace{0.2cm}
	\caption%
	{%
		\footnotesize
		Eight cases with \tf{gemv} and \tf{gemm} for the mode-$q$ tensor-matrix multiplication.
		%Argument for \tf{gemv} and \tf{gemm} with 
		Arguments \tf{T}, \tf{M}, \tf{N}, etc. of the BLAS are chosen with respect to the tensor order $p$, layout $\mbpi$ of $\mubA$, $\mbB$, $\mubC$ and contraction mode $q$ where \tf{T} specifies if $\mbB$ is transposed.
		\tf{gemm*} denotes multiple \tf{gemm} calls with different tensor slices.
		Argument $\bar{n}_q$ for case 6 and 7 is given by $\bar{n}_q = (\prod_r^p n_r)/n_q$.
		%\vspace{-0.5cm}
	}
	\label{tab:mapping_rm_cm}
\end{table*}
Algorithm \ref{alg:ttm.sequential.coalesced} is the starting point for BLAS-based algorithms.
It computes the mode-$q$ tensor-matrix product by recursively multiplying tensor slices with the matrix for $q \neq \pi_1$.
Instead of optimizing the multiplication, it is possible to insert a \tf{gemm} routine in the base case and to compute slice-matrix products.
Additionally, there are seven other (corner) cases where a single \tf{gemv} or \tf{gemm} call suffices.
All eight cases are listed in table \ref{tab:mapping_rm}.
The arguments of \tf{gemv} or \tf{gemm} are chosen depending on the tensor order $p$, tensor layout $\mbpi$ and contraction mode $q$ except for parameter \tf{CBLAS\_ORDER} which is set to \tf{CblasRowMajor}.
The \tf{CblasColMajor} format can be used as well if the following case descriptions are changed accordingly.
The parameter arguments are given in our \tf{C++} library.
Note that with table \ref{tab:mapping_rm} all linear tensor layout are supported with no limitations on tensor order and contraction mode.

%Note , all linear tensor layouts can be supported by setting the remaining parameters of \tf{gemm}.

%TODO: previously explain how CBLAS is called and what options one has, i.e. explain the design space
%TODO: explain the table for B format (already explained for RM) and CBLAS multiplication (already explained for RM) as on subsubsection and include two other subsection explaining what changes if we take B.format CM and another subsection explaining how the parameters change if it is CM.



\begin{comment}
\begin{table*}[t]
%\captionsetup{width=0.7\textheight}
\centering
\footnotesize
%\scriptsize
\begin{tabular}{ c c c c c c c c c c c c c c } % 
\toprule
Case \ & Order $p$ \ & Layout $\mbpi_{\mubA,\mubC}$ \ & Mode $q$ & Routine & \tf{T} & \tf{M} & \tf{N} & \tf{K} & \tf{A} & \tf{LDA} & \tf{B} & \tf{LDB} & \tf{LDC} \\
\midrule
1 & $1$ & -       & $1$      & \tf{gemv} & -       & $m$   & $n_1$ & -     & $\mbB$  & $n_1$ & $\mubA$  & - & - \\
\midrule
2 & $2$ & $(1,2)$ & $1$      & \tf{gemm(rm)} & $\mbB$  & $n_2$ & $m$   & $n_1$ & $\mubA$ & $n_1$ & $\mbB$   & $n_1$ & $m$   \\
  & $2$ & $(1,2)$ & $1$      & \tf{gemm(cm)} & $\mbB$  & $m$   & $n_2$ & $n_1$ & $\mbB$  & $n_1$ & $\mubA$  & $n_1$ & $m$   \\
3 & $2$ & $(1,2)$ & $2$      & \tf{gemm(rm)} & -       & $m$   & $n_1$ & $n_2$ & $\mbB$  & $n_2$ & $\mubA$  & $n_1$ & $n_1$ \\
  & $2$ & $(1,2)$ & $2$      & \tf{gemm(cm)} & -       & $n_1$ & $m$   & $n_2$ & $\mubA$ & $n_1$ & $\mbB$   & $n_2$ & $n_1$ \\  
4 & $2$ & $(2,1)$ & $1$      & \tf{gemm(rm)} & -       & $m$   & $n_2$ & $n_1$ & $\mbB$  & $n_1$ & $\mubA$  & $n_2$ & $n_2$ \\
  & $2$ & $(2,1)$ & $1$      & \tf{gemm(cm)} & -       & $n_2$ & $m$   & $n_1$ & $\mubA$ & $n_2$ & $\mbB$   & $n_1$ & $n_2$ \\
5 & $2$ & $(2,1)$ & $2$      & \tf{gemm(rm)} & $\mbB$  & $n_1$ & $m$   & $n_2$ & $\mubA$ & $n_2$ & $\mbB$   & $n_2$ & $m$   \\
  & $2$ & $(2,1)$ & $2$      & \tf{gemm(cm)} & $\mbB$  & $m$   & $n_1$ & $n_2$ & $\mbB$  & $n_2$ & $\mubA$  & $n_2$ & $m$   \\
\midrule
6 & $>2$ & any    & $\pi_1$  & \tf{gemm(rm)} & $\mbB$  & $\mbnq$ & $m$     & $n_q$ & $\mubA$ & $n_q$ & $\mbB$  & $n_q$ & $m$\\
  & $>2$ & any    & $\pi_1$  & \tf{gemm(cm)} & $\mbB$  & $m$     & $\mbnq$ & $n_q$ & $\mbB$  & $n_q$ & $\mubA$ & $n_q$ & $m$\\
7 & $>2$ & any    & $\pi_p$  & \tf{gemm(rm)} & -       & $m$     & $\mbnq$ & $n_q$ & $\mbB$  & $n_q$ & $\mubA$  & $\mbnq$ & $\mbnq$ \\
  & $>2$ & any    & $\pi_p$  & \tf{gemm(cm)} & -       & $\mbnq$ & $m$     & $n_q$ & $\mubA$  & $\mbnq$ & $\mbB$  & $n_q$ & $\mbnq$ \\
\midrule
8 & $>2$ & any & \ $\pi_2,..,\pi_{p-1}$ \ & \tf{gemm(rm)*} & - & $m$ & $n_{\pi_1}$ & $n_q$ & $\mbB$ & $n_q$ & $\mubA$ & $w_{q}$  & $w_{q}$ \\
  & $>2$ & any & \ $\pi_2,..,\pi_{p-1}$ \ & \tf{gemm(cm)*} & - & $n_{\pi_1}$ & $m$ & $n_q$ & $\mubA$ & $w_{q}$ & $\mbB$ & $n_q$ & $w_{q}$ \\
\bottomrule \\
\end{tabular}
%\vspace{0.2cm}
\caption%
{%
\footnotesize
Eight cases with \tf{gemv} and \tf{gemm} for the mode-$q$ tensor-matrix multiplication.
%Argument for \tf{gemv} and \tf{gemm} with 
Arguments \tf{T}, \tf{M}, \tf{N}, etc. of the BLAS are chosen with respect to the tensor order $p$, layout $\mbpi$ and contraction mode $q$ where \tf{T} specifies if $\mbB$ is transposed.
\tf{gemm*} denotes multiple \tf{gemm} calls with different tensor slices.
Argument $\bar{n}_q$ for case 6 and 7 is given by $\bar{n}_q = 1/n_q \prod_r^p n_r$.
Matrix $\mbB$ has the row-major format.
%\vspace{-0.5cm}
}
\label{tab:mapping_rm}
\end{table*}
\end{comment}

%We apply highly optimized routines to fully or partly execute tensor contractions as it is done in \cite{li:2015:input, shi:2016:tensor.contraction}.
%The function and parameter configurations for the tensor multiplication can be divided into eight cases.

%Table \ref{tab:mapping} extends the finding in \cite{dinapoli:2014:towards.efficient.use} precisely defining the mapping for any storage format. 
%It also complies with the findings in \cite{li:2015:input}.

\tit{Case 1:}
If $p=1$, The tensor-vector product $\mubA \times_1 \mbB$ can be computed with a \tf{gemv} operation where $\mubA$ is an order-$1$ tensor $\mba$ of length $n_1$ such that $\mba^T \cdot \mbB$.

\tit{Case 2-5:}
If $p=2$, $\mubA$ and $\mubC$ are order-$2$ tensors with dimensions $n_1$ and $n_2$.
In this case the tensor-matrix product can be computed with a single \ttt{gemm}.
If $\mbA$ and $\mbC$ have the column-major format with $\mbpi=(1,2)$, \tf{gemm} either executes $\mbC = \mbA \cdot \mbB^T$ for $q =1$ or $\mbC = \mbB \cdot \mbA$ for $q=2$.
Reshaping both matrices using $\rho$ with $\mbrho = (2,1)$, \tf{gemm} interprets $\mbC$ and $\mbA$ as matrices in row-major format although both are stored column-wise.
If $\mbA$ and $\mbC$ have the row-major format with $\mbpi=(2,1)$, \tf{gemm} either executes $\mbC = \mbB \cdot \mbA$ for $q =1$ or $\mbC = \mbA \cdot \mbB^T$ for $q=2$. 
The transposition of $\mbB$ is necessary for the cases 2 and 5 which is independent of the chosen layout.

\tit{Case 6-7 :}
% If the order of $\mubA$ and $\mubC$ is greater than $2$ 
%the contraction mode $q$ is equal to $\pi_1$ 
If $p>2$ and if $q=\pi_1$(case 6), a single \tf{gemm} with the corresponding arguments executes $\mbC = \mbA \cdot \mbB^T$ and computes a tensor-matrix product $\mubC = \mubA \times_{\pi_1} \mbB$.
% for any storage layout of $\mubA$ and $\mubC$
Tensors $\mubA$ and $\mubC$ are flattened with $\varphi_{2,p}$ to row-major matrices $\mbA$ and $\mbC$.
%$f_{2,p}$, see subsection \ref{sec:preliminaries:flattening}.
Matrix $\mbA$ has $\bar{n}_{\pi_1} = \bar{n} / n_{\pi_1}$ rows and $n_{\pi_1}$ columns while matrix $\mbC$ has the same number of rows and $m$ columns.
If $\pi_p=q$ (case 7), $\mubA$ and $\mubC$ are flattened with $\varphi_{1,p-1}$ to column-major matrices $\mbA$ and $\mbC$.
Matrix $\mbA$ has $n_{\pi_p}$ rows and $\bar{n}_{\pi_p} =  \bar{n} / n_{\pi_p}$ columns while $\mbC$ has $m$ rows and the same number of columns.
In this case, a single \tf{gemm} executes $\mbC = \mbB \cdot \mbA$ and computes $\mubC = \mubA \times_{\pi_p} \mbB$.
Noticeably, the desired contraction are performed without copy operations, see subsection \ref{sec:preliminaries:flattening.reshaping}.

\tit{Case 8 $(p>2)$:}
If the tensor order is greater than $2$ with $\pi_1\neq q$ and $\pi_p \neq q$, the modified baseline algorithm \ref{alg:ttm.sequential.coalesced} is used to successively call $\bar{n} / (n_q \cdot n_{\pi_1})$ times \tf{gemm} with different tensor slices of $\mubC$ and $\mubA$.
Each \tf{gemm} computes one slice $\mubC_{\pi_1,q}'$ of the tensor-matrix product $\mubC$ using the corresponding tensor slices $\mubA_{\pi_1,q}'$ and the matrix $\mbB$.
The matrix-matrix product $\mbC = \mbB \cdot \mbA$ is performed by interpreting both tensor slices as row-major matrices $\mbA$ and $\mbC$ which have the dimensions $(n_q,n_{\pi_1})$ and $(m,n_{\pi_1})$, respectively.
Please note that Algorithm 2 in \cite{li:2015:input} suggests to transpose matrix $\mbB$.

\subsection{BLAS-Based Algorithms with Subtensors}
\label{sec:design:blas.based.algorithm.subtensors}
The eighth case can be further optimized by slicing larger subtensors and use additional dimensions for the slice-matrix multiplication.
% by utilizing larger subtensors than tensor slices
%This is accomplished 
The selected dimensions must adhere to flatten the subtensor into a matrix without reordering or copying elements, see lemma 4.1 in \cite{li:2015:input}.
%We will use our flattening operation which does not copy or reorder elements, see section \ref{sec:preliminaries:flattening.reshaping}.
% see section \ref{sec:preliminaries:flattening.reshaping}.
The number of additional modes is $\mhq-1$ with $\mhq = \mbpi^{-1}(q)$ and the corresponding modes are $\pi_1,\pi_2,\dots,\pi_{\mhq-1}$.
%with dimensions $n_{\pi_1},\dots,n_{\pi_{\mhq-1}}, n_{q}$
Applying flattening $\varphi_{1,\mhq-1}$ and reshaping $\rho$ with $\mbrho = (2,1)$ on a subtensor of $\mubA$ yields a row-major matrix $\mbA$ with shape $(n_q,\prod_{r=1}^{\mhq-1} n_{\pi_r})$.
Analogously, tensor $\mubC$ becomes a row-major matrix with the shape $(m, \prod_{r=1}^{\mhq-1} n_{\pi_r})$.
This description supports all linear tensor layouts and generalizes lemma 4.2 in \cite{li:2015:input}.

Algorithm \ref{alg:ttm.sequential.coalesced} needs a minor modification so that \tf{gemm} can be used with flattened subtensors instead of tensor slices.
The non-base case of the modified algorithm only iterates over dimensions with indices that are larger than $\mhq$, omitting the first $\mhq$ modes $\mbpi_{1,\mhq} = (\pi_1, \dots, \pi_{\mhq})$ with $\pi_{\mhq} = q$.
The conditions in line 2 and 4 are changed to $1 < r \leq \mhq$ and $\mhq < r$, respectively.
The single indices of the subtensors $\mubA_{\mbpi_{1,\mhq}}'$ and $\mubC_{\mbpi_{1,\mhq}}'$ are given by the loop induction variables that belong to the $\pi_r$-th loop with $\mhq+1 \leq r \leq p$.  
 
\subsection{Parallel BLAS-based Algorithms}
\label{subsec:parallel.multi-loops}
Next, three parallel approaches for the eighth case.
Note that cases 1 to 7 already call a multi-threaded \tf{gemm}.
%\vspace{-1em}

\subsubsection{Sequential Loops and Parallel Matrix Multiplication}
A simple approach is to not modify algorithm \ref{alg:ttm.sequential.coalesced} and sequentially call a multi-threaded \tf{gemm} in the base case as described in subsection \ref{sec:design:blas.based.algorithm.slices}.
This is beneficial if $q = \pi_{p-1}$, the inner dimensions $n_{\pi_1},\dots,n_{q}$ are large or if the outer-most dimension $n_{\pi_{p}}$ is smaller than the available processor cores.
However, when the above conditions are not met, the algorithm executes multi-threaded \tf{gemm} with small subtensors.
This might lead to a low utilization of available computational resources.
This algorithm version will be referred to as \tf{<seq-loops,par-gemm>}.
% that is executable with subtensors or tensor slices
%\vspace{-1em}

\subsubsection{Parallel Loops and Multithreaded Matrix Multiplication}
A more advanced version of the above algorithm executes a single-threaded \tf{gemm} in parallel with all available (free) modes.
The number of free modes depends on the tensor slicing.
If subtensors are used, all $\pi_{\mhq+1}, \dots, \pi_{p}$ modes are free and can be used for parallel execution.
In case of tensor slices, only dimensions with indices $\pi_1$ and $\pi_{\mhq}$ are free.
%The corresponding maximum degree of parallelism for both cases is $\prod_{r=\mhq+1}^{p} n_{\pi_r}$ and $\prod_{r=1}^{p} n_{r} / (n_{\pi_1} n_{\pi_{\mhq}})$, respectively.

%whereas 
%todo: Note that the number of free modes depends on the tensor order $p$ and contraction mode $q$.
%\footnote{In \cite{li:2015:input}, free modes are called loop modes and are elements of the set $M_L$.}.

%The parallel execution of free loops is accomplished with OpenMP directives and by flattening (collapsing) all loops within the tree-recursion into one or two loops depending on the available fusible loops.

Using tensor slices for the multiplication, $\mubA$ and $\mubC$ are flattened twice with $\varphi_{\pi_{\mhq+1},\pi_p}$ and $\varphi_{\pi_{2},\pi_{\mhq-1}}$.
The flattened tensors are of order $4$ with dimensions $n_{\pi_1}$, $\mhn_{\pi_2}$, $n_{q}$ or $m$, $\mhn_{\pi_4}$ where $\mhn_{\pi_2} = \prod_{r=2}^{\mhq-1} n_{\pi_r}$ and $\mhn_{\pi_4} = \prod_{r=\mhq+1}^{p} n_{\pi_r}$.
This approach transforms the tree-recursion into two loops.
The outer loop iterates over $\mhn_{\pi_4}$ while the inner loop iterates over $\mhn_{\pi_2}$ calling \tf{gemm} with slices $\mubA_{\pi_1,q}'$ and $\mubC_{\pi_1,q}'$.
%Hence, only two contraction modes $\pi_1$ and $\pi_q$ are involved in the matrix multiplication.
%\footnote{In \cite{li:2015:input}, contraction modes are component modes and are elements of the set $M_C$.}.
Both loops are parallelized using \tf{omp parallel for} together with the \tf{collapse(2)} and the \tf{num\_threads} clause which specifies the thread number.


If subtensors are used, both tensors are flattened twice with $\varphi_{\pi_{\mhq+1},\pi_p}$ and $\varphi_{\pi_{1},\pi_{\mhq-1}}$. 
The flattened tensors are of order $3$ with dimensions $\mhn_{\pi_1}$, $n_{q}$ or $m$, $\mhn_{\pi_4}$ where $\mhn_{\pi_1} = \prod_{r=1}^{\mhq-1} n_{\pi_r}$ and $\mhn_{\pi_4} = \prod_{r=\mhq+1}^{p} n_{\pi_r}$.
The corresponding algorithm consists of one loops which iterates over $\mhn_{\pi_4}$ calling single-threaded \tf{gemm} with multiple subtensors $\mubA_{\mbpi',q}'$ and $\mubC_{\mbpi',q}'$ with $\mbpi' = (\pi_1,\dots,\pi_{\mhq-1})$.

Both algorithm variants will be referred to as \tf{<par-loops,seq-gemm>} which can be used with subtensors or tensor slices.
Note that \tf{<seq-loops,par-gemm>} and \tf{<par-loops,seq-gemm>} are opposing versions where either \tf{gemm} or the free loops are performed in parallel.
The all-parallel version \tf{<par-loops,par-gemm>} executes available loops in parallel where each loop thread executes a multi-threaded \tf{gemm} with either subtensors or tensor slices.
%\vspace{-1em}

\subsubsection{Multithreaded Batched Matrix Multiplication}
The next version of the base algorithm is a modified version of the general subtensor-matrix approach that calls a single batched \tf{gemm} for the eighth case.
The subtensor dimensions and remaining \tf{gemm} arguments remain the same.
The library implementation is responsible how subtensor-matrix multiplications are executed and if subtensors are further divided into smaller subtensors or tensor slices.
This version will be referred to as the \tf{<gemm\_batch>} variant.
